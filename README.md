# Google Maps Sentiment Analysis API

Sistema avanzado de extracci√≥n y an√°lisis de rese√±as de Google Maps. Este proyecto combina **Web Scraping** (Playwright), **Procesamiento de Lenguaje Natural** (Transformers) y **APIs REST** (FastAPI) para generar insights autom√°ticos sobre negocios.

## üöÄ Caracter√≠sticas Principales

*   **Scraping Indetectable**: Uso de Playwright con estrategias de evasi√≥n de bots y autenticaci√≥n mediante Cookies.
*   **An√°lisis de Sentimientos (NLP)**: Integraci√≥n de modelos Transformers (Robertuito/BETO) para clasificar rese√±as en Espa√±ol (Positivo, Negativo, Neutral) con score de confianza.
*   **API REST**: Endpoint r√°pido constru√≠do con FastAPI para integrar en otros sistemas.
*   **Cache Persistente**: Uso de **PostgreSQL** para almacenar resultados y evitar scraping redundante.
*   **Cloud Ready**: Configurado para despliegue en Render (Docker/Native).

---

## üõ†Ô∏è Instalaci√≥n

1.  **Clonar el repositorio**:
    ```bash
    git clone <repo-url>
    cd modelScrap
    ```

2.  **Instalar dependencias**:
    Se recomienda usar un entorno virtual (`venv`).
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```
    *Nota: Esto descargar√° librer√≠as pesadas como PyTorch y Transformers.*

3.  **Configurar Variables de Entorno**:
    Crea un archivo `.env` o configura las variables en tu sistema:
    ```bash
    # URL de conexi√≥n a PostgreSQL (Opcional en local, obligatorio en Prod)
    DATABASE_URL=postgresql://user:password@host:port/dbname
    
    # Opcional: Saltar carga de modelos al inicio (para debug r√°pido)
    # SKIP_NLP_LOAD=true
    ```

---

## üç™ Configuraci√≥n de Autenticaci√≥n (Google Login)

Google bloquea los logins automatizados en la nube. Para solucionarlo, usamos **Cookies de Sesi√≥n**.

1.  **Ejecutar el asistente de login local**:
    ```bash
    python scraper.py --setup-cookies
    ```
2.  Se abrir√° un navegador Chrome.
3.  Inicia sesi√≥n manualmente en Google.
4.  Presiona `ENTER` en la terminal cuando hayas terminado.
5.  Se generar√° el archivo `cookies.json`.
6.  **Importante**: Si despliegas en Render, aseg√∫rate de subir este archivo o gestionarlo como secret.

---

## üíª Uso

### 1. Servidor API (Recomendado)

Levanta el servidor FastAPI. La primera vez descargar√° el modelo de IA (~500MB).

```bash
uvicorn api:app --reload
```

- **Swagger UI**: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
- **Endpoint**: `POST /analyze`

#### Ejemplo de Petici√≥n
```bash
curl -X POST "http://127.0.0.1:8000/analyze" \
     -H "Content-Type: application/json" \
     -d '{
           "maps_url": "https://maps.app.goo.gl/Ti7ixa3owkmGMdTo9",
           "limit": 20,
           "forceUpdate": false
         }'
```

#### Respuesta JSON
```json
{
  "business_name": "Nombre del Negocio",
  "total_reviews": 20,
  "average_rating": 4.5,
  "sentiment_summary": {
    "POS": 15,
    "NEG": 2,
    "NEU": 3
  },
  "reviews": [
    {
      "username": "Usuario 1",
      "rating": 5,
      "review_text": "Excelente servicio...",
      "sentiment": "POS",
      "confidence": 0.98
    }
  ],
  "cached": false
}
```

### 2. Uso como Script CLI
Si solo necesitas el CSV sin la API:

```bash
python scraper.py --url "https://maps.app.goo.gl/..." --limit 50
```
Generar√° un archivo `reviews_<hash>.csv`.

---

## ‚òÅÔ∏è Despliegue en Render

Este proyecto est√° optimizado para Render.

1.  Crear nuevo **Web Service**.
2.  Entorno: **Python 3**.
3.  Comando de Build:
    ```bash
    pip install -r requirements.txt && playwright install chromium
    ```
4.  Comando de Inicio:
    ```bash
    uvicorn api:app --host 0.0.0.0 --port $PORT
    ```
5.  **Variables de Entorno**:
    - `DATABASE_URL`: Tu conexi√≥n a PostgreSQL interna/externa de Render.

---

## ‚ö†Ô∏è Aviso Legal

Este software es una herramienta de prueba de concepto (PoC) con fines **educativos y de investigaci√≥n acad√©mica**. 
- El scraping de sitios web puede violar los T√©rminos de Servicio de Google.
- No utilice esta herramienta para extracci√≥n masiva no autorizada o comercial.
- El autor no se hace responsable del mal uso de este software.
